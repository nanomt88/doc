#2018.4.26 - 线上环境CPU跑完问题分析

#背景

2018.4.26号，晚上上线**银联垫资代付的时候，出现服务器CPU 跑满 400%的情况。当时没有找到原因，考虑有可能是新加的代码的问题，所以回退代码，下来在找原因。

之前这块的功能是经过测试人员测试，也做过压力测试，并没有出现问题。而且我记得代码中也没有写与线程相关的代码，所以一时感觉找不到线索，只能下来再找。



#分析原因

CPU跑满的情况，一般都是线程死循环导致。但是新加的**银联代付接口，代码里面没有写new Thread()相关的代码。在出现问了之后，由于太过慌张，没有收集服务器jvm相关的信息，导致这个问题这个问题没有太多线索，只能通过代码和日志入手。

检查日志后发现，有两个点比较可疑：

1.	网络异常
		
		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.087 [nioEventLoopGroup-3-4] com.lakala.quickpayment.netty4.MessageServerHandler.channelRead - 【无卡支付】请求信息:com.lakala.quickpayment.dto.CRequestParamDTO@3a65690c[
		  length=482
		  bankType=9226
		  tradeType=0088
		  reqBody=<root><txnType>02</txnType><txnNo>00000861804262394453</txnNo><acqInsCode>499******</acqInsCode><txnDate>20180426</txnDate><sndTime>223049</sndTime><settleMethod>00</settleMethod><merId>822*****</merId><merName>拉卡拉商户</merName><payeeBankNo>*****</payeeBankNo><payeeAcctNo>62220202*******</payeeAcctNo><payeeAcctName>刘**</payeeAcctName><currencyCode>156</currencyCode><txnAmt>000000000001</txnAmt><remark>拉卡拉测试12345678901234567890</remark></root>
		]!
		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.089 [nioEventLoopGroup-3-4] com.lakala.quickpayment.netty4.MessageServerHandler.channelRead - ctx是:io.netty.channel.DefaultChannelHandlerContext@162dca79!	
		ERROR [quickPaymentPro-prd14] 2018-04-26 22:32:49.048 [nioEventLoopGroup-3-4] com.lakala.quickpayment.netty4.MessageServerHandler.exceptionCaught - 【无卡支付】网络异常.请联系管理人员io.netty.handler.timeout.ReadTimeoutException: null

	最开始一直怀疑是网络这块的问题。代码里面没有新起线程的代码，所以推测最有可能是网络连接这块没有控制好，在网络出现中断的情况下，连接没有释放然后导致连接死锁。在日志中一共找到四处 <font color='red'>网络异常[ReadTimeoutException]</font> ，所以重点检查这一块的代码。

	服务端连接这块，使用的是Netty框架，版本是3.8，在查看了项目中跟Netty相关的代码之后，没有太大的收获。应该是自己对Netty的掌握还是不够深入吧。考虑到线上用了这么久的Netty了，应该不大可能会是这样的问题吧。。。懵逼中……

	一上午的努力没啥收获，之后换个角度了，去看一下日志中第二个可疑点。

2.	错误的交易类型:0088

		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.378 [pool-4-thread-9] com.lakala.quickpayment.service.impl.QuickNetDeductServiceProcess.sendMessageToBank - 【无卡支付】获取银行路由服务:com.lakala.quickpayment.banks.unionpay.UnionpayFundSettlementNetServiceProcess@4bf42872
		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.378 [pool-4-thread-9] com.lakala.quickpayment.banks.unionpay.UnionpayFundSettlementNetServiceProcess.sendMessageToBank - 【无卡支付——中国银联资金结算系统】错误的交易类型:0088!
		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.379 [pool-4-thread-9] com.lakala.quickpayment.banks.unionpay.UnionpayFundSettlementNetServiceProcess.sendMessageToBank - 【无卡支付——中国银联资金结算系统】[找不到对应的交易类型]交易信息处理结束!
		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.380 [pool-4-thread-9] com.lakala.quickpayment.netty4.MessageRecvInitializeTask.run - 【无卡支付】返回给支付接口的信息:0000010892260088ET<errorInfo><errorCode>ET</errorCode><errorMessage>找不到对应的交易类型!</errorMessage></errorInfo>
		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.380 [pool-4-thread-9] com.lakala.quickpayment.netty4.MessageRecvInitializeTask.run - ctx是:io.netty.channel.DefaultChannelHandlerContext@365174ad!
		INFO  [quickPaymentPro-prd14] 2018-04-26 22:30:49.381 [pool-4-thread-9] com.lakala.quickpayment.netty4.MessageRecvInitializeTask.run - 【无卡支付】消息处理3豪秒.

	第一个可疑点检查完之后，没有收获，于是转向第二个可疑点进行检查。

	0088交易类型是中国银联资金结算系统的单笔代付请求，因没有匹配上，然后返回代收付系统 <font color='red'>【找不到对应的交易类型】</font> 这个错误。这个之前是测试过的，而且代码中的编码也没有修改过，所以这个类型肯定是可以匹配单笔代付的，不应该返回错误。越想越懵逼，难道服务器启动之后就不正常了？？？是什么导致出这种不不可能的错误？？？

	于是只能顺这个流程查看相关的代码，通过对比日志输出的地方和代码进行比对，慢慢所需代码出错的范围。


		String transTypeName = TradeType.getNameByValue(tradeType);
        if ("找不到对应的交易类型".equals(transTypeName)) {
            log.info("【无卡支付——中国银联资金结算系统】错误的交易类型:{}!", tradeType);
            resp.setResultCode(QuickpayReturnCode.ERROR_TRADETYPE);
            resp.setErrorMessage("找不到对应的交易类型!");
        }

	根据日志对比，错误出现在TradeType.getNameByValue 。查看TradeType的代码：
		
		public class TradeType {
			public final static HashMap<String, TradeTypeEnum> ALL = new HashMap<String, TradeTypeEnum>();

			public static String getNameByValue(final String code) {
				init();
				final TradeTypeEnum tradeType = ALL.get(code);
				if (tradeType == null) {
					return TradeTypeEnum.NOT_FOUND.getTradeTypeName();
				} else {
					return tradeType.getTradeTypeName();
				}
			}
			private static void init() {
				if (ALL.isEmpty()) {
					TradeTypeEnum.init();
				}
			}
		
			public enum TradeTypeEnum {
				ENUM1,ENUM2,ENUM3...
				
				public static void init() {
					for (final TradeTypeEnum element : values()) {
						ALL.put(element.tradeType, element);
					}
				}
			}
		}
		
	以上是TradeType主要代码，前前后后扫了好两遍，感觉内容很简单，应该不会有啥问题啊。游离的目光，突然停顿在 静态全局变量的HashMap上三秒，哪里感觉怪怪的，突然内心泛起一点小波澜，啊哈哈哈哈 O(∩_∩)O~ ，WTF，问题很有可能就在这，HashMap在并发的情况下会导致死锁！不知道为啥突然想到这一点，终于从大海捞针的变成找到方向了。
	
#重现

以前知道HashMap在并发的情况下，一边扩容一边取值会导致死锁。但是还没有现实中还没有碰到过，要先进行验证一遍。

先写一个测试类测试一下：

![](https://i.imgur.com/f59Ai6F.png)

运行四五次之后，就有碰到一次线程锁死，进程无法终止，CPU 跑满的情况。进一步确认，这里的代码有问题。接下来就是要在测试环境进行重现。只有在测试环境进行重现了，这个解释才有说服力。


仔细分析一下重现的条件

- 系统刚刚启动完成之后，TradeType这个类还没有加载。TradeType中的静态成员变量是在在这个类刚调用的时候才会加载。所以只要加载过一次之后就不会再出现。
- 并发访问。 在第一次访问的时候，就并发请求，这样TradeType中的 hashMap就会出现一个线程在加载，一个线程访问取值的情况。这样可能出现死锁。


然后联系测试MM，在测试环境进行重新。先停掉浙江银联代付接口的请求，只用银联资金结算通路的单笔代付接口测试就可以了。 测试MM先在测试环境上传好一个批次、20笔代付的交易，我重新启动服务（没有其他请求访问），MM在测试环境代收付管理系统审批之后，就会将交易一笔笔发到代收付核心系统，然后再转发到Java通路。经过四次模拟，终于重现CPU跑满的情况

![](https://i.imgur.com/QMsGtXm.png)

通过图可以看到 进程ID 6252的Java通路就是 银联资金结算系统的服务，cup已经跑到快800%了。反过来在屡一下昨天的情况：

1. 当时服务刚刚启动，还没有任何请求，在22:30分的时候才一下子来了几个请求。
2. 测试MM上传了一个批次20笔交易的代付文件，审批之后一下子就发过来了。统计了22/23服务器的请求，确实20个，一边10个（说明负载均衡还是比较均衡的哈）。

以上测试环境的模拟重现了昨天晚上的情况，总算是找到原因了~~~


#如何修复

修改很简单，两种方式：

1. 最简单的方式：HashMap改为 ConcurrentHashMap 即可。经过多次单元测试，没有问题
2. 将JDK 1.8之后就修复了这个问题，目前线上用的是1.7，升级即可。

再次敲黑板，HashMap是线程不安全的，并发情况下会导致死锁。并发情况下使用ConcurrentHashMap。在用Spring是，都是单例的，写成员变量和静态变量的时候一定要小心又小心

#影响

TradeType 这个类是在 common包中，基本上每个通路的交易类型，就会使用到TradeType类，也就会触发这个问题。涉及面比较广，应该是绝大多数服务都会有这个问题，需要升级修复。因为对所有的服务都不是很了解，暂时还无法仔细评估。


#总结

1. 线上监控还是比较重要。

	线上监控还是比较重要，系统的报警短信最好直接发到相关的人。昨天系统报警应该是从22:46分出现，到23:10 左右我才知道服务器CPU负载过高。

	服务器的监控现在太弱了，关于 jvm GC、jvm Thread、IO、disk 现在应该都还是没有的，建议以后都加上，并且给研发开相应的权限，可以平时实时查看。

2. 老代码中，感觉不对的要敢于改。
	
	以前的代码很多都是跑了很久的，但不一定合理。所以没有问题一般是不会动的，有些明显的错误应该改修改的就修改了。

	在查这个问题的时候，也发现了相关可能存在隐患的代码：

	
		public class MessageServer {
			public static void main(String[] args) throws Exception {
				// Configure the server.
				ServerBootstrap bootstrap = new ServerBootstrap(new NioServerSocketChannelFactory(
						Executors.newCachedThreadPool(), Executors.newCachedThreadPool()));
				...
			}
		}

	以上代码，是启动Java通路的启动类，应该是大部分服务都是一样的。存在以下问题：boss、work线程池都是使用的无限制容量线程池。这个是有可能会导致cpu跑满的问题
	
3. 发现问题之后，没有搜集线程环境，所以下来之后只能看日志，但是日志的信息比较有限。当CPU跑满的这种情况，需要第一时间停用服务，不然会导致其他服务资源耗尽。所以在线上分析，查询cpu、jvm gc 这种情况肯定不合适。阿里有个工程师提供了一个线上环境收集的脚本，可以快速搜集，然后恢复生产环境。
	

	[JVM飙高排查脚本](https://yq.aliyun.com/articles/55 "JVM飙高排查脚本-结构分析")
	
	备注：在做jvm dump的时候会导致服务暂停，这个得小心！！